{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052f007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e86530fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Output schema (Pydantic)\n",
    "# -----------------------------\n",
    "class PlaceGuess(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    city: Optional[str] = None\n",
    "    country: Optional[str] = None\n",
    "\n",
    "\n",
    "class PlaceAnalysis(BaseModel):\n",
    "    input_type: Literal[\"place_photo\", \"not_a_place\", \"ambiguous\"]\n",
    "    place_guess: PlaceGuess\n",
    "    confidence: float = Field(ge=0.0, le=1.0)\n",
    "    what_i_see: List[str]\n",
    "    significance: List[str]\n",
    "    response: str\n",
    "\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=PlaceAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "327799b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2) Helpers\n",
    "# -----------------------------\n",
    "def preprocess_image_to_b64(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Make a reasonable-size JPEG and return base64 (no data-url prefix).\n",
    "    Keeps request sizes sane and ImgBB happy.\n",
    "    \"\"\"\n",
    "    p = Path(image_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    img = Image.open(p).convert(\"RGB\")\n",
    "    img.thumbnail((1600, 1600))\n",
    "\n",
    "    tmp = p.with_suffix(\".tmp.jpg\")\n",
    "    img.save(tmp, format=\"JPEG\", quality=90)\n",
    "\n",
    "    b64 = base64.b64encode(tmp.read_bytes()).decode(\"utf-8\")\n",
    "    tmp.unlink(missing_ok=True)\n",
    "    return b64\n",
    "\n",
    "\n",
    "def upload_to_imgbb(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Upload to ImgBB and return a public image URL.\n",
    "    Endpoint pattern commonly used:\n",
    "      POST https://api.imgbb.com/1/upload?key=API_KEY\n",
    "    with form field 'image'. :contentReference[oaicite:1]{index=1}\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"IMGBB_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Missing IMGBB_API_KEY in environment\")\n",
    "\n",
    "    b64 = preprocess_image_to_b64(image_path)\n",
    "\n",
    "    url = f\"https://api.imgbb.com/1/upload\"\n",
    "    params = {\"key\": api_key}\n",
    "    data = {\"image\": b64}\n",
    "\n",
    "    r = requests.post(url, params=params, data=data, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    payload = r.json()\n",
    "\n",
    "    if not payload.get(\"success\"):\n",
    "        raise RuntimeError(f\"ImgBB upload failed: {payload}\")\n",
    "\n",
    "    # ImgBB typically returns .data.url (public page) and .data.display_url (direct image)\n",
    "    data_obj = payload[\"data\"]\n",
    "    return data_obj.get(\"display_url\") or data_obj[\"url\"]\n",
    "\n",
    "\n",
    "def serpapi_reverse_image(public_image_url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Use SerpApi Google Lens (best general option).\n",
    "    SerpApi docs: engine=google_lens, parameter 'url', and 'type' controls results. :contentReference[oaicite:2]{index=2}\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Missing SERPAPI_API_KEY in environment\")\n",
    "\n",
    "    params = {\n",
    "        \"engine\": \"google_lens\",\n",
    "        \"url\": public_image_url,   # required by google_lens :contentReference[oaicite:3]{index=3}\n",
    "        \"type\": \"all\",             # all/products/exact_matches/visual_matches :contentReference[oaicite:4]{index=4}\n",
    "        \"hl\": \"en\",\n",
    "        \"api_key\": api_key,\n",
    "    }\n",
    "\n",
    "    r = requests.get(\"https://serpapi.com/search\", params=params, timeout=90)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def extract_serp_evidence(serp_json: dict, max_items: int = 8) -> dict:\n",
    "    \"\"\"\n",
    "    Pull out the most useful fields for place ID:\n",
    "    - titles/sources from exact matches\n",
    "    - titles/sources from visual matches\n",
    "    - any knowledge graph / entity hints if present\n",
    "    Keep it compact so the LLM doesn't drown.\n",
    "    \"\"\"\n",
    "    evidence = {\n",
    "        \"knowledge_graph\": {},\n",
    "        \"exact_matches\": [],\n",
    "        \"visual_matches\": [],\n",
    "    }\n",
    "\n",
    "    kg = serp_json.get(\"knowledge_graph\") or {}\n",
    "    # Keep only a few common keys if present\n",
    "    for k in [\"title\", \"type\", \"description\", \"website\", \"address\", \"location\"]:\n",
    "        if k in kg and kg[k]:\n",
    "            evidence[\"knowledge_graph\"][k] = kg[k]\n",
    "\n",
    "    exact = serp_json.get(\"exact_matches\") or []\n",
    "    for item in exact[:max_items]:\n",
    "        evidence[\"exact_matches\"].append({\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"source\": item.get(\"source\"),\n",
    "            \"link\": item.get(\"link\"),\n",
    "        })\n",
    "\n",
    "    visual = serp_json.get(\"visual_matches\") or []\n",
    "    for item in visual[:max_items]:\n",
    "        evidence[\"visual_matches\"].append({\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"source\": item.get(\"source\"),\n",
    "            \"link\": item.get(\"link\"),\n",
    "        })\n",
    "\n",
    "    return evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d65e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) PromptTemplate\n",
    "# -----------------------------\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"format_instructions\", \"serp_evidence_json\"],\n",
    "    template=(\n",
    "        \"You are a careful place-identification assistant.\\n\"\n",
    "        \"The user provides ONLY a photo, but you also receive reverse-image evidence.\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1) Decide: input_type is one of place_photo | not_a_place | ambiguous.\\n\"\n",
    "        \"2) Use the reverse-image evidence as grounding. Do NOT guess wildly.\\n\"\n",
    "        \"3) If evidence is weak or contradictory, set input_type=ambiguous and keep confidence low.\\n\"\n",
    "        \"4) Provide significance ONLY if you are confident the place is correctly identified.\\n\"\n",
    "        \"5) Output MUST be valid JSON matching the schema exactly.\\n\\n\"\n",
    "        \"Reverse-image evidence (JSON):\\n\"\n",
    "        \"{serp_evidence_json}\\n\\n\"\n",
    "        \"{format_instructions}\\n\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) LangChain chain (LCEL)\n",
    "# -----------------------------\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0.2)\n",
    "\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id = \"openai/gpt-oss-120b\",\n",
    "#     task = \"text-generation\",  \n",
    "# )\n",
    "\n",
    "# model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "def build_message(inputs: dict) -> List[HumanMessage]:\n",
    "    image_path = inputs[\"image_path\"]\n",
    "\n",
    "    public_url = upload_to_imgbb(image_path)\n",
    "    serp = serpapi_reverse_image(public_url)\n",
    "    evidence = extract_serp_evidence(serp)\n",
    "\n",
    "    prompt_text = prompt.format(\n",
    "        format_instructions=parser.get_format_instructions(),\n",
    "        serp_evidence_json=json.dumps(evidence, ensure_ascii=False, indent=2),\n",
    "    )\n",
    "\n",
    "    # Send BOTH the text + the public image URL to the model\n",
    "    # (LangChain supports image_url content parts for Gemini). :contentReference[oaicite:5]{index=5}\n",
    "    msg = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": prompt_text},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": public_url}},\n",
    "        ]\n",
    "    )\n",
    "    return [msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6dd671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableLambda(build_message)\n",
    "    | model\n",
    "    | (lambda ai_msg: ai_msg.content)\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "282d29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"img/img3.jpg\"  # Example image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db154d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "(Request ID: req_01kcpyxz7secn9gjk5a20trkaa)\n\nBad request:\n{'message': 'messages[0].content must be a string', 'type': 'invalid_request_error', 'param': 'messages[0].content'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:402\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://router.huggingface.co/groq/openai/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result: PlaceAnalysis = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.model_dump_json(indent=\u001b[32m2\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# result: dict = chain.invoke({\"image_path\": image_path})\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# print(json.dumps(result, indent=2))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\langchain_huggingface\\chat_models\\huggingface.py:655\u001b[39m, in \u001b[36mChatHuggingFace._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    648\u001b[39m     message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    649\u001b[39m     params = {\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    651\u001b[39m         **params,\n\u001b[32m    652\u001b[39m         **({\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m    653\u001b[39m         **kwargs,\n\u001b[32m    654\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(answer)\n\u001b[32m    657\u001b[39m llm_input = \u001b[38;5;28mself\u001b[39m._to_chat_prompt(messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:915\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    887\u001b[39m parameters = {\n\u001b[32m    888\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    889\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    906\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    907\u001b[39m }\n\u001b[32m    908\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    909\u001b[39m     inputs=messages,\n\u001b[32m    910\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    914\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:275\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\My files\\jvai_env\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:458\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n\u001b[32m    455\u001b[39m     message = (\n\u001b[32m    456\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m endpoint:\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBad request:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    457\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(BadRequestError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m    461\u001b[39m     message = (\n\u001b[32m    462\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    463\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    464\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMake sure your token has the correct permissions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m     )\n",
      "\u001b[31mBadRequestError\u001b[39m: (Request ID: req_01kcpyxz7secn9gjk5a20trkaa)\n\nBad request:\n{'message': 'messages[0].content must be a string', 'type': 'invalid_request_error', 'param': 'messages[0].content'}"
     ]
    }
   ],
   "source": [
    "result: PlaceAnalysis = chain.invoke({\"image_path\": image_path})\n",
    "print(result.model_dump_json(indent=2))\n",
    "\n",
    "# result: dict = chain.invoke({\"image_path\": image_path})\n",
    "# print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd64476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] preprocess_image_to_b64\n",
      "  ok | b64 length: 19108\n",
      "\n",
      "[2] upload_to_imgbb\n",
      "  ok | url: https://i.ibb.co/DDnJFDkF/f97501121e1d.jpg\n",
      "\n",
      "[3] serpapi_reverse_image\n",
      "  ok | returned keys: ['search_metadata', 'search_parameters', 'ai_overview', 'visual_matches', 'related_content']\n",
      "\n",
      "[4] extract_serp_evidence\n",
      "  ok | evidence preview:\n",
      " {\n",
      "  \"knowledge_graph\": {},\n",
      "  \"exact_matches\": [],\n",
      "  \"visual_matches\": [\n",
      "    {\n",
      "      \"title\": \"Universitato Jahangirnagar - Vikipedio\",\n",
      "      \"source\": \"Wikipedia\",\n",
      "      \"link\": \"https://eo.wikipedia.org/wiki/Universitato_Jahangirnagar\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The first light ft. Shaheed Minar, JU\",\n",
      "      \"source\": \"Instagram\",\n",
      "      \"link\": \"https://www.instagram.com/p/DN6BLkyCRLX/\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"JU suspends Sunday classes, postpones exams over JUCSU polls ...\",\n",
      "      \"source\": \"Amader Barta\",\n",
      "      \"link\": \"https://www.amaderbarta.net/en/news/ju-suspends-sunday-classes-postpones-exams-over-jucsu-polls-342761\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Somoy - Jahangirnagar University (JU) authorities have ...\",\n",
      "      \"source\": \"Facebook\",\n",
      "      \"link\": \"https://www.facebook.com/photo.php?fbid=1539150404392982&set=a.826162359025127&type=3\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Protesters block Dhaka-Aricha highway\",\n",
      "      \"source\": \"Dhaka Tribune\",\n",
      "      \"link\": \"https://www.dhakatribune.com/bangladesh/353642/protesters-block-dhaka-aricha-highway\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"JU set to hold undergraduate admission tests in December's ...\",\n",
      "      \"source\": \"Daily Observer\",\n",
      "      \"lin\n",
      "\n",
      "[5] chain.invoke\n",
      "  ok | final output:\n",
      " {\n",
      "  \"input_type\": \"place_photo\",\n",
      "  \"place_guess\": {\n",
      "    \"name\": \"Shaheed Minar\",\n",
      "    \"city\": \"Savar\",\n",
      "    \"country\": \"Bangladesh\"\n",
      "  },\n",
      "  \"confidence\": 0.8,\n",
      "  \"what_i_see\": [\n",
      "    \"A large red brick monument with a tall, angular structure in the center.\",\n",
      "    \"Paved pathways leading to the monument.\",\n",
      "    \"Grassy areas with manicured bushes on either side of the pathways.\",\n",
      "    \"Buildings in the background.\",\n",
      "    \"A bright blue sky with scattered clouds.\"\n",
      "  ],\n",
      "  \"significance\": [\n",
      "    \"The monument appears to be the Shaheed Minar at Jahangirnagar University, a prominent landmark in Bangladesh.\",\n",
      "    \"Shaheed Minar (Martyrs' Monument) is a national monument in Dhaka, Bangladesh, built in memory of those killed in the Bengali Language Movement demonstrations in 1952.\"\n",
      "  ],\n",
      "  \"response\": \"The photo shows the Shaheed Minar, a significant monument located at Jahangirnagar University in Savar, Bangladesh. This monument is a symbol of the Bengali Language Movement.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PlaceAnalysis(input_type='place_photo', place_guess=PlaceGuess(name='Shaheed Minar', city='Savar', country='Bangladesh'), confidence=0.8, what_i_see=['A large red brick monument with a tall, angular structure in the center.', 'Paved pathways leading to the monument.', 'Grassy areas with manicured bushes on either side of the pathways.', 'Buildings in the background.', 'A bright blue sky with scattered clouds.'], significance=['The monument appears to be the Shaheed Minar at Jahangirnagar University, a prominent landmark in Bangladesh.', \"Shaheed Minar (Martyrs' Monument) is a national monument in Dhaka, Bangladesh, built in memory of those killed in the Bengali Language Movement demonstrations in 1952.\"], response='The photo shows the Shaheed Minar, a significant monument located at Jahangirnagar University in Savar, Bangladesh. This monument is a symbol of the Bengali Language Movement.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# def test_all(image_path: str):\n",
    "#     print(\"\\n[1] preprocess_image_to_b64\")\n",
    "#     b64 = preprocess_image_to_b64(image_path)\n",
    "#     print(\"  ok | b64 length:\", len(b64))\n",
    "\n",
    "#     print(\"\\n[2] upload_to_imgbb\")\n",
    "#     public_url = upload_to_imgbb(image_path)\n",
    "#     print(\"  ok | url:\", public_url)\n",
    "\n",
    "#     print(\"\\n[3] serpapi_reverse_image\")\n",
    "#     serp = serpapi_reverse_image(public_url)\n",
    "#     print(\"  ok | returned keys:\", list(serp.keys())[:12])\n",
    "\n",
    "#     print(\"\\n[4] extract_serp_evidence\")\n",
    "#     evidence = extract_serp_evidence(serp)\n",
    "#     print(\"  ok | evidence preview:\\n\", json.dumps(evidence, indent=2)[:1200])\n",
    "\n",
    "#     print(\"\\n[5] chain.invoke\")\n",
    "#     out = chain.invoke({\"image_path\": image_path})\n",
    "#     print(\"  ok | final output:\\n\", out.model_dump_json(indent=2))\n",
    "\n",
    "#     return out\n",
    "\n",
    "# # usage:\n",
    "# test_all(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jvai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
